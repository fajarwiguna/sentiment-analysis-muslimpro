{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3fa2781",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc2d2806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b8f1648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ADVAN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ed2dd2",
   "metadata": {},
   "source": [
    "## Eksplorasi Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61c7092a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  rating\n",
      "0                                       sangat bagus       5\n",
      "1                                                bes       5\n",
      "2                                        terimakasih       5\n",
      "3                                        terimakasih       5\n",
      "4  iklan gak bisa keluar, stak di shopee terus ik...       1\n"
     ]
    }
   ],
   "source": [
    "# Baca data\n",
    "df = pd.read_csv('data_muslimpro_reviews.csv')\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d9dcab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   review  10000 non-null  object\n",
      " 1   rating  10000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 156.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c02cabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jumlah Missing Value per Kolom:\n",
      "review    0\n",
      "rating    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cek jumlah missing value per kolom\n",
    "print(\"\\nJumlah Missing Value per Kolom:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81a13503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jumlah total data: 10000\n"
     ]
    }
   ],
   "source": [
    "# Jumlah data total\n",
    "print(f\"\\nJumlah total data: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ac77072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kolom yang tersedia:\n",
      "Index(['review', 'rating'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Cek apakah ada kolom label\n",
    "print(\"\\nKolom yang tersedia:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e85bba",
   "metadata": {},
   "source": [
    "## Labeling Sentimen Otomatis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79bc3243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribusi Sentimen:\n",
      "sentiment\n",
      "positif    5820\n",
      "negatif    3380\n",
      "netral      800\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Mapping rating ke sentimen\n",
    "def rating_to_sentiment(rating):\n",
    "    if rating <= 2:\n",
    "        return 'negatif'\n",
    "    elif rating == 3:\n",
    "        return 'netral'\n",
    "    else:\n",
    "        return 'positif'\n",
    "\n",
    "# Buat kolom label\n",
    "df['sentiment'] = df['rating'].apply(rating_to_sentiment)\n",
    "\n",
    "# Cek distribusi label\n",
    "print(\"Distribusi Sentimen:\")\n",
    "print(df['sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178a71a9",
   "metadata": {},
   "source": [
    "## Preprocessing Teks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cefc2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  \\\n",
      "0                                       sangat bagus   \n",
      "1                                                bes   \n",
      "2                                        terimakasih   \n",
      "3                                        terimakasih   \n",
      "4  iklan gak bisa keluar, stak di shopee terus ik...   \n",
      "\n",
      "                                  clean_review  \n",
      "0                                        bagus  \n",
      "1                                          bes  \n",
      "2                                  terimakasih  \n",
      "3                                  terimakasih  \n",
      "4  iklan gak stak shopee iklannya lihat sholat  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ADVAN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('indonesian'))\n",
    "\n",
    "def clean_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Hapus URL\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    # Hapus angka dan tanda baca\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # Tokenisasi dan hapus stopword\n",
    "    tokens = text.split()\n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Terapkan pembersihan teks\n",
    "df['clean_review'] = df['review'].astype(str).apply(clean_text)\n",
    "\n",
    "# Cek hasil\n",
    "print(df[['review', 'clean_review']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fce888e",
   "metadata": {},
   "source": [
    "# LSTM (Deep Learning)\n",
    "Menggunakan arsitektur LSTM dengan layer embedding untuk klasifikasi sentimen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd6185d",
   "metadata": {},
   "source": [
    "### Preprocessing Teks untuk LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "282ca0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenisasi untuk LSTM\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=5000)  # 5000 kata paling sering\n",
    "\n",
    "# Fit tokenizer dengan teks yang sudah dibersihkan\n",
    "tokenizer.fit_on_texts(df['clean_review'])\n",
    "\n",
    "# Ubah teks menjadi urutan angka\n",
    "X_seq = tokenizer.texts_to_sequences(df['clean_review'])\n",
    "\n",
    "# Padding agar panjang setiap sequence sama\n",
    "X_pad = pad_sequences(X_seq, padding='post', maxlen=100)  # maxlen bisa disesuaikan\n",
    "\n",
    "# Labeling dengan LabelEncoder untuk konversi ke numerik\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(df['sentiment'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83afc353",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11dbfd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data menjadi train dan test (80:20)\n",
    "X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm = train_test_split(\n",
    "    X_pad, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040ce1a7",
   "metadata": {},
   "source": [
    "### Membangun Model LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ed7b0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model LSTM\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100))  # +1 untuk memasukkan indeks 0\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=False)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))  # 3 kelas sentimen: positif, netral, negatif\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0f57bd",
   "metadata": {},
   "source": [
    "### Training Model LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5c7e848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping untuk menghindari overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d3a2c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 88ms/step - accuracy: 0.6725 - loss: 0.7306 - val_accuracy: 0.8955 - val_loss: 0.2847\n",
      "Epoch 2/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 90ms/step - accuracy: 0.9195 - loss: 0.2370 - val_accuracy: 0.9610 - val_loss: 0.1231\n",
      "Epoch 3/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 100ms/step - accuracy: 0.9674 - loss: 0.1131 - val_accuracy: 0.9735 - val_loss: 0.0799\n",
      "Epoch 4/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.9779 - loss: 0.0752 - val_accuracy: 0.9795 - val_loss: 0.0616\n",
      "Epoch 5/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.9806 - loss: 0.0639 - val_accuracy: 0.9835 - val_loss: 0.0552\n",
      "Epoch 6/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.9841 - loss: 0.0523 - val_accuracy: 0.9840 - val_loss: 0.0499\n",
      "Epoch 7/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.9835 - loss: 0.0515 - val_accuracy: 0.9825 - val_loss: 0.0478\n",
      "Epoch 8/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.9851 - loss: 0.0451 - val_accuracy: 0.9860 - val_loss: 0.0454\n",
      "Epoch 9/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.9856 - loss: 0.0477 - val_accuracy: 0.9870 - val_loss: 0.0431\n",
      "Epoch 10/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.9873 - loss: 0.0448 - val_accuracy: 0.9850 - val_loss: 0.0444\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_lstm, y_train_lstm, epochs=10, batch_size=64, \n",
    "                    validation_data=(X_test_lstm, y_test_lstm), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493b1f91",
   "metadata": {},
   "source": [
    "### Evaluasi Model LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5cd3482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step\n",
      "Akurasi LSTM: 0.987\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       676\n",
      "           1       0.97      0.93      0.95       160\n",
      "           2       1.00      0.99      1.00      1164\n",
      "\n",
      "    accuracy                           0.99      2000\n",
      "   macro avg       0.98      0.97      0.98      2000\n",
      "weighted avg       0.99      0.99      0.99      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluasi model di data test\n",
    "y_pred_lstm = model.predict(X_test_lstm)\n",
    "y_pred_lstm = np.argmax(y_pred_lstm, axis=1)  # Ubah probabilitas jadi kelas\n",
    "\n",
    "print(\"Akurasi LSTM:\", accuracy_score(y_test_lstm, y_pred_lstm))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_lstm, y_pred_lstm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2b788e",
   "metadata": {},
   "source": [
    "### Inference dengan Model LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45707238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Prediksi sentimen dengan LSTM: positif\n"
     ]
    }
   ],
   "source": [
    "# Contoh inferensi\n",
    "sample = [\"aplikasi ini sangat membantu dalam mendalami Islam\"]\n",
    "\n",
    "# Preprocessing\n",
    "sample_cleaned = [clean_text(sample[0])]\n",
    "sample_seq = tokenizer.texts_to_sequences(sample_cleaned)\n",
    "sample_pad = pad_sequences(sample_seq, padding='post', maxlen=100)\n",
    "\n",
    "# Prediksi\n",
    "prediction_lstm = model.predict(sample_pad)\n",
    "predicted_class = le.inverse_transform([np.argmax(prediction_lstm)])\n",
    "\n",
    "print(\"Prediksi sentimen dengan LSTM:\", predicted_class[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58b837e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "# Pastikan folder model ada\n",
    "os.makedirs('model', exist_ok=True)\n",
    "\n",
    "# Simpan model LSTM\n",
    "model.save('model/lstm_model.h5')\n",
    "\n",
    "# Simpan tokenizer\n",
    "with open('model/tokenizer.pkl', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle)\n",
    "\n",
    "# Simpan label encoder\n",
    "with open('model/label_encoder.pkl', 'wb') as handle:\n",
    "    pickle.dump(le, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efefe871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
